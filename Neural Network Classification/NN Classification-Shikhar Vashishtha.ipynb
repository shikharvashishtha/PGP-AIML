{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imporing relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "from tensorflow.keras import optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "h5f = h5py.File('F:\\PGP AIML\\Project 7\\data\\SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split in to Train, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = h5f['X_train'][:]\n",
    "y_train1 = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test1 = h5f['y_test'][:]\n",
    "\n",
    "h5f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train1, y_train1, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "training_set_shape = X_train.shape\n",
    "print(training_set_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "validation_set_shape = X_val.shape\n",
    "print(validation_set_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "test_set_shape = X_test.shape\n",
    "print(test_set_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing a few samples from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  5\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[100])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_train[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_test[0])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_test1[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepossesing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping X data: (n, 32, 32) => (n, 1024)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_val = X_val.reshape((X_val.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y data into categorical (one-hot encoding)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test1 = to_categorical(y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model:\n",
    "   # Initializing the loop with possible best Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_loop1(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model1 = Sequential()\n",
    "    \n",
    "    model1.add(Dense(100, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))    \n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(70, kernel_initializer='he_normal'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    \n",
    "\n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model1.fit(X_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model1.evaluate(X_train, y_train, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy at lr = 0.00001 and Lambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 7s 211us/sample - loss: 2.7338 - acc: 0.0998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.641143658501761, 0.10017857]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "train_and_test_loop1(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 8s 233us/sample - loss: 2.6887 - acc: 0.1047s - loss: \n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6944 - acc: 0.1003\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6842 - acc: 0.1062\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6897 - acc: 0.10392s - loss: 2.7073  - ETA: 1s - loss: 2.684\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6874 - acc: 0.1031\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6916 - acc: 0.10490s - loss: 2.6969 - acc: 0.\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6884 - acc: 0.1051\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6833 - acc: 0.10342s - loss:\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 88us/sample - loss: 2.6918 - acc: 0.1017\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6867 - acc: 0.1030\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6843 - acc: 0.10381s - loss\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6876 - acc: 0.1026\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 88us/sample - loss: 2.6883 - acc: 0.10212s - loss: 2.6936 - acc: 0. - ETA: 2s - loss: 2.6909 - acc - ETA: 1s - loss: 2.\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6885 - acc: 0.1014\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6998 - acc: 0.1007\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6835 - acc: 0.1049\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6943 - acc: 0.1035\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6831 - acc: 0.1049\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6915 - acc: 0.1040\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6885 - acc: 0.1048\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6907 - acc: 0.1023\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 88us/sample - loss: 2.6842 - acc: 0.1014\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6911 - acc: 0.10390s - loss: 2.6933 - ac - ETA: 0s - loss: 2.6914 - acc: 0.10\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6852 - acc: 0.1042\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6907 - acc: 0.10000s - loss: 2.6913 - acc: 0.09\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6852 - acc: 0.1017\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6890 - acc: 0.10200s - loss: 2.6897 - acc: 0.1\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6849 - acc: 0.10252s - loss: 2.6710 - acc:  - ETA: 2s - l\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6893 - acc: 0.10102\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6848 - acc: 0.1030\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6840 - acc: 0.1027\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6769 - acc: 0.1025\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6870 - acc: 0.10162s - loss: 2 - ETA: 0s - loss: 2.6905 - \n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6838 - acc: 0.1038\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6873 - acc: 0.10291s - loss: 2.\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6849 - acc: 0.10292s - lo\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6867 - acc: 0.1019\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6887 - acc: 0.10152s - loss: 2.6873 - acc: 0 - ETA: 2s - los\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6793 - acc: 0.1033\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6763 - acc: 0.1050\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6947 - acc: 0.1018\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6827 - acc: 0.10430s - loss: 2.6803 - a\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6817 - acc: 0.10610s - loss: 2.6804 - acc:\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6813 - acc: 0.10511s - loss: 2.6816 \n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6784 - acc: 0.10542\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6758 - acc: 0.10581s - loss: 2.6770 -\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6751 - acc: 0.10560s - loss: 2.6723 - acc: 0 - ETA: 0s - loss: 2.6746 - acc: 0.105\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6791 - acc: 0.1052\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6817 - acc: 0.1045\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6781 - acc: 0.1060\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6734 - acc: 0.10251s - loss: 2.6747 - acc: - ETA: 0s - loss: 2.6724 - a\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6767 - acc: 0.10412s -\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6821 - acc: 0.1019\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6842 - acc: 0.1054\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6738 - acc: 0.10491s - loss: \n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6857 - acc: 0.1013\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6731 - acc: 0.10231s - loss: 2\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6763 - acc: 0.10462s - lo\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6766 - acc: 0.10260s - loss: 2.6751 - \n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.6773 - acc: 0.1025\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.6748 - acc: 0.1040\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 4s 104us/sample - loss: 2.6774 - acc: 0.1050\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.6826 - acc: 0.1039s - loss: 2.6842 - ac\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.6812 - acc: 0.1045\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 4s 107us/sample - loss: 2.6717 - acc: 0.1047\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6752 - acc: 0.10530s - loss: 2.6732 - acc: \n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.6730 - acc: 0.10551s - loss: 2.6695\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6690 - acc: 0.10231s - loss: 2.6637 - ETA: 0s - loss: 2.6666 - acc: 0\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.6736 - acc: 0.1018\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.6746 - acc: 0.10212s - lo\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6755 - acc: 0.1040\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6834 - acc: 0.1017\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.6757 - acc: 0.1029\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6724 - acc: 0.1055\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6671 - acc: 0.10240s - loss: 2.6679 - acc: 0.102\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6669 - acc: 0.1053\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6726 - acc: 0.1039\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6705 - acc: 0.10441s - loss: 2.65\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6748 - acc: 0.10492s\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6812 - acc: 0.10272s - \n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6660 - acc: 0.10390s - loss: 2.6642 - acc: 0.1\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6648 - acc: 0.1065\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 2.6735 - acc: 0.1039\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6660 - acc: 0.10571s - loss: 2.6701 -  - ETA: 0s - loss: 2.6704 - ac\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6663 - acc: 0.1028\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6764 - acc: 0.1039\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6734 - acc: 0.1029\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6775 - acc: 0.10432s\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6706 - acc: 0.10401s - loss: 2.6\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 2.6662 - acc: 0.1054\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6692 - acc: 0.1029\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6714 - acc: 0.1040\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6652 - acc: 0.10621s - loss: 2\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.6656 - acc: 0.1046\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6655 - acc: 0.1029\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6703 - acc: 0.10521s - loss: 2.6788 -  - ETA: 0s - loss: 2.6773 - \n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6637 - acc: 0.10452s\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6682 - acc: 0.10351s - loss: 2.6\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6707 - acc: 0.10292\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6617 - acc: 0.1042\n",
      "Try 1/100: Best_val_acc: [2.393485362416222, 0.10955357], lr: 2.088615665235475e-06, Lambda: 1.0804721919499883e-05\n",
      "\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 7s 210us/sample - loss: 2.5238 - acc: 0.1108s - loss: 2.5457 - acc: 0\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 2.3075 - acc: 0.1523\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.1427 - acc: 0.2178\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.9494 - acc: 0.3060\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.7726 - acc: 0.37670s - loss: 1.7874 - acc:\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 1.6338 - acc: 0.4278\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 1.5279 - acc: 0.47042s\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 1.4357 - acc: 0.51211s - loss: 1.4508\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 1.3678 - acc: 0.53452s - l\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.3084 - acc: 0.5635\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 1.2757 - acc: 0.5753\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.2204 - acc: 0.5969\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.1834 - acc: 0.61061s - loss: 1.1893 - acc:  - ETA: 1s - loss: 1.18\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.1636 - acc: 0.61940s - loss: 1.1673 - acc:  - ETA: 0s - loss: 1.1639 - acc: 0.6\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.1173 - acc: 0.63901s - loss: 1.1256 - acc: 0. - ETA: 1s - loss: 1.1212 -  - ETA: 0s - loss: 1.1162 - acc: 0.6\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.0942 - acc: 0.64640s - loss: 1.0973 - acc: 0.6\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.0693 - acc: 0.6549\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 1.0489 - acc: 0.66812s - l\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.0306 - acc: 0.67632s - \n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 1.0134 - acc: 0.6788\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 0.9895 - acc: 0.68660s - loss: 0.9945 - acc:\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.9765 - acc: 0.6941\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.9525 - acc: 0.7014\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 0.9310 - acc: 0.70780s - loss: 0.9210 - \n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.9295 - acc: 0.70790s - loss: 0.9354 - acc\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.9076 - acc: 0.7153\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.9025 - acc: 0.7161\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.8874 - acc: 0.72511s - loss:\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.8748 - acc: 0.72622s - loss:  - ETA: 0s - loss: 0.8750 - acc: 0.7\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.8552 - acc: 0.73652s -\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.8481 - acc: 0.73601s - loss: 0.\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 0.8527 - acc: 0.73651s - loss: 0.843\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.8340 - acc: 0.7412\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.8348 - acc: 0.74341s - loss: 0\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.8132 - acc: 0.7485\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.8101 - acc: 0.7496\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.8059 - acc: 0.75052s -\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.7936 - acc: 0.75781s - loss: 0.7915 - acc: - ETA: 1s - loss: 0.7949 - \n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.7950 - acc: 0.7559\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.7879 - acc: 0.7574\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 104us/sample - loss: 0.7761 - acc: 0.7614\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 0.7770 - acc: 0.7623\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.7683 - acc: 0.7633\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 0.7585 - acc: 0.76602s - loss: 0.7551 -  - ETA: 1s - loss: 0.7559 - - ETA: 0s - loss: 0.7582 - acc: 0.76\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 0.7639 - acc: 0.7663\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.7541 - acc: 0.7685\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.7492 - acc: 0.77071s - loss: 0.7456 - a - ETA: 1s - loss: 0.7411 -\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.7378 - acc: 0.77342s - \n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.7412 - acc: 0.7744\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.7345 - acc: 0.77322s - \n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.7313 - acc: 0.7754\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.7210 - acc: 0.7810\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.7204 - acc: 0.7809\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 3s 89us/sample - loss: 0.7243 - acc: 0.7805\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 0.7107 - acc: 0.7830\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 0.7004 - acc: 0.78732s\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 3s 90us/sample - loss: 0.6961 - acc: 0.78702s\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.7076 - acc: 0.78491s - loss: 0.7095  - ETA: 0s - loss: 0.7095 - acc: \n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6915 - acc: 0.78792s - los - ETA: 0s - loss: 0.6926 - acc: 0\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.6865 - acc: 0.79091s - loss: 0.6771 - ac - ETA: 0s - loss: 0.6831 - acc: \n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.6833 - acc: 0.79361s - loss:\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.6749 - acc: 0.79591s - loss: 0.6736 \n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6813 - acc: 0.7937\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6959 - acc: 0.78691s - loss: 0.6982 \n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6718 - acc: 0.7953\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6797 - acc: 0.7922\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6709 - acc: 0.7984\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6609 - acc: 0.8014\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6659 - acc: 0.7970\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 0.6678 - acc: 0.7984\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6607 - acc: 0.7985\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6619 - acc: 0.7986\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6526 - acc: 0.8005\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6427 - acc: 0.80470s - loss: 0.6422 - acc: \n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.6467 - acc: 0.8034\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.6483 - acc: 0.80382s - loss: 0.6416 - acc: 0.8 - ETA: 2s - los\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 0.6453 - acc: 0.80392s \n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 0.6408 - acc: 0.8054\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.6383 - acc: 0.80322s - loss\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6457 - acc: 0.8045\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.6340 - acc: 0.8069\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6370 - acc: 0.8071\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6299 - acc: 0.80922s - lo\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6379 - acc: 0.8069\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6330 - acc: 0.80700s - loss: 0.6322 - acc: 0.80\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6219 - acc: 0.81090s - loss: 0.6229 - acc: 0.\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6261 - acc: 0.80780s - loss: 0.6233 - acc\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6273 - acc: 0.8082\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 0.6275 - acc: 0.80770s - loss: 0.6233 - acc: \n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.6144 - acc: 0.8134\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6097 - acc: 0.8140\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 0.6166 - acc: 0.81312s - \n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.6189 - acc: 0.8128\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6170 - acc: 0.81161s - loss: 0.614\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 0.6095 - acc: 0.81501s - loss: 0\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.6139 - acc: 0.8136\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.6117 - acc: 0.8176\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 0.5981 - acc: 0.8190\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 0.5959 - acc: 0.8189\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 0.5957 - acc: 0.8186\n",
      "Try 2/100: Best_val_acc: [0.6108700076100372, 0.8087798], lr: 0.02098856385734849, Lambda: 0.0003801922142446604\n",
      "\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 7s 208us/sample - loss: 7.6140 - acc: 0.0980s - loss: 6.7279 - a\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 9.9846 - acc: 0.1045\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.7730 - acc: 0.1030\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.9911 - acc: 0.1009\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 10.5057 - acc: 0.0989\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 10.3223 - acc: 0.0995\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 10.3207 - acc: 0.0997s - l\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2999 - acc: 0.0998\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 10.3126 - acc: 0.1016s - los\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 10.3471 - acc: 0.1017\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.4695 - acc: 0.0994\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 10.3088 - acc: 0.1016\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 10.3144 - acc: 0.1012\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.4687 - acc: 0.0993\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3909 - acc: 0.0995s - loss: 10.\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4561 - acc: 0.1010\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2878 - acc: 0.1004\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 10.2925 - acc: 0.0993\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.2912 - acc: 0.0986\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3544 - acc: 0.0983\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4067 - acc: 0.1006s - loss: 10.3964 - acc\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 10.4483 - acc: 0.1018\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.4135 - acc: 0.0977s - loss: 10.39\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4453 - acc: 0.1016s - loss: 10.4388 - acc: 0.\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3972 - acc: 0.1016\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.4766 - acc: 0.0987\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3253 - acc: 0.1014\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.2802 - acc: 0.1007s - loss: 10.2469 - acc - ETA: 0s - loss: 10.2635 - acc: 0.10 - ETA: 0s - loss: 10.2621\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 10.2757 - acc: 0.0982\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2974 - acc: 0.0993\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4453 - acc: 0.0964s - loss: 10.4682 - acc: \n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.5642 - acc: 0.0988\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3860 - acc: 0.1008s - loss: 10.3782 - acc: 0.10\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.4333 - acc: 0.1006\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.3276 - acc: 0.1003\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3981 - acc: 0.1006\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4168 - acc: 0.1001\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3376 - acc: 0.1016\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3250 - acc: 0.0985\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.2847 - acc: 0.1016\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2681 - acc: 0.0984\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.2590 - acc: 0.0991\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2674 - acc: 0.1003\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.2735 - acc: 0.1025s - loss: 10.2854 - acc: 0.\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2612 - acc: 0.1013\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3693 - acc: 0.0967\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.4886 - acc: 0.0975s - loss: 10.48\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3804 - acc: 0.1013\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3901 - acc: 0.0991\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2955 - acc: 0.1012- ETA: 1s -\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.2566 - acc: 0.1001s - loss: 10.2228 - acc: \n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3012 - acc: 0.1015\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2536 - acc: 0.1014\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3634 - acc: 0.1000\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.2984 - acc: 0.1005s - loss: 10.2486\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3482 - acc: 0.1005\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3054 - acc: 0.1007\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.2741 - acc: 0.1018s - loss: 10.2593 - acc: 0.10 - ETA: 0s - loss: 10.2740 - acc: 0.10\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.3351 - acc: 0.0984\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3882 - acc: 0.0993s - loss: 10.3832 - acc\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4136 - acc: 0.0997s - loss: 10.3960 - ETA: 0s - loss: 10.4093\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.4859 - acc: 0.0989\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.4490 - acc: 0.1003\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.4785 - acc: 0.0974\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.3173 - acc: 0.1003s -\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3273 - acc: 0.1010s\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.4061 - acc: 0.0994\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4120 - acc: 0.0994\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4034 - acc: 0.0996\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3272 - acc: 0.1031s - loss: 10.3341 - acc - ETA: 2s - loss: 10.3757 - acc: 0.10 - ETA - ETA: 0s - loss: 10.3384 -\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2870 - acc: 0.0975\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.2698 - acc: 0.1003\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3654 - acc: 0.0990\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 10.2655 - acc: 0.0983\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.3496 - acc: 0.0998s - loss: 10.3256 - acc: \n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.3353 - acc: 0.0991\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.3321 - acc: 0.1007\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 10.4109 - acc: 0.1017s -\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3758 - acc: 0.0970s - loss: 1\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.2666 - acc: 0.0998s - loss: 10.1864 - acc: 0.10 -\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.2773 - acc: 0.0987\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.2578 - acc: 0.1013\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 10.2739 - acc: 0.0989s - l - ETA: 1s - l\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3589 - acc: 0.0993\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 10.3730 - acc: 0.1002\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3936 - acc: 0.1018\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.2548 - acc: 0.1010s - loss: 10.2679 -\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 10.3492 - acc: 0.0993\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.3477 - acc: 0.1019\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.4484 - acc: 0.0957s - loss: 10.48\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3903 - acc: 0.0999\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 10.3880 - acc: 0.0993\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.3475 - acc: 0.1001\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.2584 - acc: 0.1004\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.3479 - acc: 0.0988\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 10.2694 - acc: 0.1002s - los\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 10.2740 - acc: 0.1005\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 10.2533 - acc: 0.1029\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s 91us/sample - loss: 10.2505 - acc: 0.1010\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 10.2468 - acc: 0.1022\n",
      "Try 3/100: Best_val_acc: [10.229801650728499, 0.099107146], lr: 19.727602117141362, Lambda: 1.4169087121098585e-06\n",
      "\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 7s 212us/sample - loss: 2.7567 - acc: 0.0939\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7032 - acc: 0.1013\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6694 - acc: 0.1016\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6470 - acc: 0.1043\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6193 - acc: 0.1010\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.5890 - acc: 0.1078\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.5658 - acc: 0.11041s - loss: 2.570\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.5595 - acc: 0.1122\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.5444 - acc: 0.1090\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.5192 - acc: 0.1169\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.5067 - acc: 0.1204\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.5002 - acc: 0.11772s -\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.4949 - acc: 0.11911s - loss: 2.4952 -  - ETA: 0s - loss: 2.4928 - acc\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.4800 - acc: 0.12121s - loss: 2.4\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.4710 - acc: 0.1224\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.4621 - acc: 0.1233\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.4474 - acc: 0.1283\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.4406 - acc: 0.1290\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.4264 - acc: 0.13450s - loss: 2.4288 - \n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.4200 - acc: 0.13382s - l\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.4085 - acc: 0.1366\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.4027 - acc: 0.13811s - loss: 2.4081 - \n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.3966 - acc: 0.13931s - loss: 2.3997 - a - ETA: 0s - loss: 2.3948 - acc: 0.\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.3859 - acc: 0.1431\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.3769 - acc: 0.1477\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.3735 - acc: 0.1445\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.3599 - acc: 0.15300s - loss: 2.3616 - acc: 0.15\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.3546 - acc: 0.1523\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.3499 - acc: 0.1503\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.3403 - acc: 0.15360s - loss: 2.3408 - a\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.3336 - acc: 0.1583\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.3218 - acc: 0.15840s - loss: 2.3246 - \n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.3170 - acc: 0.1632\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.3134 - acc: 0.1643\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.2956 - acc: 0.17151s - loss: \n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.2920 - acc: 0.1728\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.2890 - acc: 0.17262s - lo\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.2743 - acc: 0.1796\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.2732 - acc: 0.1793\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.2619 - acc: 0.18510s - loss: 2.2644 - acc:\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.2472 - acc: 0.1893\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.2436 - acc: 0.1882\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.2358 - acc: 0.1950\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.2282 - acc: 0.1971\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.2268 - acc: 0.19580s - loss: 2.2278 - acc: 0.1\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.2093 - acc: 0.2024\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.2098 - acc: 0.2017\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.1964 - acc: 0.2091\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.1903 - acc: 0.2104\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.1787 - acc: 0.2187\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.1756 - acc: 0.2188\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.1631 - acc: 0.2235\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.1512 - acc: 0.22762s\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.1452 - acc: 0.2304\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.1423 - acc: 0.23200s - loss: 2.1426 - acc\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.1259 - acc: 0.2398\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.1230 - acc: 0.2399\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.1177 - acc: 0.2438\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.1067 - acc: 0.24222s - \n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.0948 - acc: 0.2501\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.0892 - acc: 0.2531\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.0777 - acc: 0.25602s - loss: 2.0800 - acc: 0.2 - ETA: 1s - loss: 2\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.0680 - acc: 0.26151s - loss: 2.0604 -  - ETA: 0s - loss: 2.0677 - acc: 0.2\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.0658 - acc: 0.2625\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.0522 - acc: 0.2680\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.0429 - acc: 0.27352s \n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.0392 - acc: 0.2770\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.0354 - acc: 0.2779\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.0237 - acc: 0.28352s - loss: 2.0234 - acc: 0.288 - ETA: 2s - los\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.0134 - acc: 0.28741s - loss: 2.0118 - acc - ETA: 0s - loss: 2.0136 - acc: \n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.0018 - acc: 0.29051s - loss: 2.0043 - acc - ETA: 0s - loss: 1.9996 - acc: 0.293 - ETA: 0s - loss: 1.9992 - acc:\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.0047 - acc: 0.2885\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 1.9949 - acc: 0.2949\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.9846 - acc: 0.29590s - loss: 1.9840 - acc: 0.2\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 1.9735 - acc: 0.29992\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 1.9758 - acc: 0.3001\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 1.9611 - acc: 0.3056\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 1.9505 - acc: 0.3134\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 4s 131us/sample - loss: 1.9483 - acc: 0.3103s - los\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 1.9388 - acc: 0.3188\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 4s 129us/sample - loss: 1.9361 - acc: 0.3185\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 5s 146us/sample - loss: 1.9261 - acc: 0.3219\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 4s 122us/sample - loss: 1.9206 - acc: 0.3248s - loss: 1.9202 - acc: 0.\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 5s 135us/sample - loss: 1.9077 - acc: 0.3332\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 5s 136us/sample - loss: 1.9010 - acc: 0.3333\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 5s 159us/sample - loss: 1.8944 - acc: 0.3362\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 1.8946 - acc: 0.3324\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - ETA: 0s - loss: 1.8824 - acc: 0.337 - 4s 105us/sample - loss: 1.8828 - acc: 0.3365\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 1.8748 - acc: 0.3487\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 4s 120us/sample - loss: 1.8705 - acc: 0.3460\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 5s 153us/sample - loss: 1.8625 - acc: 0.3505\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 4s 129us/sample - loss: 1.8516 - acc: 0.3540\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 5s 138us/sample - loss: 1.8482 - acc: 0.3555\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 5s 147us/sample - loss: 1.8435 - acc: 0.3584\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 4s 128us/sample - loss: 1.8335 - acc: 0.3632s - \n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 4s 113us/sample - loss: 1.8347 - acc: 0.3590\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 4s 105us/sample - loss: 1.8271 - acc: 0.3668\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 4s 105us/sample - loss: 1.8150 - acc: 0.3693\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 1.8126 - acc: 0.3703\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 4s 116us/sample - loss: 1.8048 - acc: 0.3759\n",
      "Try 4/100: Best_val_acc: [1.5643969985416957, 0.5545238], lr: 0.0004471792520772551, Lambda: 0.0010173913490217493\n",
      "\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 8s 246us/sample - loss: 2.8406 - acc: 0.0978\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 4s 109us/sample - loss: 2.8244 - acc: 0.1003\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8203 - acc: 0.0986\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8166 - acc: 0.1023\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.8126 - acc: 0.1025\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.8047 - acc: 0.0990\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8021 - acc: 0.10311s - loss:\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7955 - acc: 0.10052s -\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7889 - acc: 0.10322s -  - ETA: 0s - loss: 2.7890 - acc: 0.1\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7946 - acc: 0.1015\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7829 - acc: 0.0997\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7822 - acc: 0.09980s - loss: 2.7824 - acc: 0.09\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7722 - acc: 0.10132s -\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7803 - acc: 0.09840s - loss: 2.7791 - acc: \n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7720 - acc: 0.09912s\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7732 - acc: 0.09991s - loss:  - ETA: 0s - loss: 2.7739 - acc: 0.099\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7648 - acc: 0.0985\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7634 - acc: 0.10162s -\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7523 - acc: 0.1012\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7560 - acc: 0.10021s - loss: 2.7636\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7574 - acc: 0.0997\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7417 - acc: 0.10291s - loss: 2.746\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7387 - acc: 0.10372s - loss: 2.7332 - acc: 0.105 - ETA: 2s - lo\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7432 - acc: 0.1000\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7360 - acc: 0.1003\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 4s 121us/sample - loss: 2.7415 - acc: 0.1007\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 4s 131us/sample - loss: 2.7361 - acc: 0.1016\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 2.7342 - acc: 0.1004\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.7148 - acc: 0.1033\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7225 - acc: 0.1001\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7188 - acc: 0.1038s - los\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7158 - acc: 0.10062s - loss:  - ETA: 0s - loss: 2.7153 - acc: 0.0\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7128 - acc: 0.1027\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 2.7069 - acc: 0.1021s - loss: 2.7071 - acc: \n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 2.7130 - acc: 0.0979\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7113 - acc: 0.1019\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 4s 105us/sample - loss: 2.6948 - acc: 0.1043\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7008 - acc: 0.1023\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6945 - acc: 0.1015\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 4s 108us/sample - loss: 2.6911 - acc: 0.1062\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6888 - acc: 0.10320s - loss: 2.6893 - acc: 0\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6899 - acc: 0.1023\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6942 - acc: 0.1017\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6798 - acc: 0.1011\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 4s 105us/sample - loss: 2.6854 - acc: 0.1028\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.6738 - acc: 0.1051s - loss: 2\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6786 - acc: 0.10232\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.6844 - acc: 0.1012\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.6780 - acc: 0.1034\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6707 - acc: 0.1060\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.6601 - acc: 0.1039\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 3s 92us/sample - loss: 2.6662 - acc: 0.1040\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6703 - acc: 0.1038\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 4s 105us/sample - loss: 2.6586 - acc: 0.1038\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6641 - acc: 0.10212s - loss: - ETA: 0s - loss: 2.6640 - acc: 0.102\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.6634 - acc: 0.1029\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 4s 108us/sample - loss: 2.6576 - acc: 0.1023\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6541 - acc: 0.10401s - loss: 2.6586\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6582 - acc: 0.1008\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6604 - acc: 0.09910s - loss: 2.6588 - acc: 0.0\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 3s 93us/sample - loss: 2.6516 - acc: 0.10212s - loss: - ETA: 0s - loss: 2.6514 - acc: 0\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6484 - acc: 0.1021\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6441 - acc: 0.10340s - loss: 2.6456 - acc: 0.\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6385 - acc: 0.1052\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 4s 108us/sample - loss: 2.6472 - acc: 0.1034\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6412 - acc: 0.1015\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6437 - acc: 0.10300s - loss: 2.6423 - acc:\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6334 - acc: 0.1049\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.6298 - acc: 0.1058s\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6368 - acc: 0.1066\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6335 - acc: 0.1043\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.6360 - acc: 0.10282s - loss\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 4s 118us/sample - loss: 2.6282 - acc: 0.1031\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6279 - acc: 0.1037\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6293 - acc: 0.1034\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6252 - acc: 0.10241s - loss: 2.6242 \n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6222 - acc: 0.1049\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6174 - acc: 0.1048\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.6226 - acc: 0.10571s - loss: 2.6267\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6173 - acc: 0.1061\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6142 - acc: 0.1070\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.6144 - acc: 0.1039\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 4s 123us/sample - loss: 2.6100 - acc: 0.1062\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.6098 - acc: 0.10712s - loss:  - ETA: 0s - loss: 2.6125 - acc: 0.1\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 3s 104us/sample - loss: 2.6143 - acc: 0.1060\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6154 - acc: 0.1065\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6103 - acc: 0.1040\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.6096 - acc: 0.1061\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.6046 - acc: 0.1066\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.6088 - acc: 0.1068\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.6040 - acc: 0.1068\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 2.6074 - acc: 0.1053s - l\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 2.6018 - acc: 0.1038\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6006 - acc: 0.1060\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 4s 106us/sample - loss: 2.6027 - acc: 0.1082\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.6033 - acc: 0.10380s - loss: 2.6009 - a\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 4s 108us/sample - loss: 2.5964 - acc: 0.1083\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.5980 - acc: 0.1070\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 4s 112us/sample - loss: 2.5965 - acc: 0.1079\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 4s 110us/sample - loss: 2.6010 - acc: 0.1040\n",
      "Try 5/100: Best_val_acc: [2.353640425772894, 0.11482143], lr: 1.423006564824899e-05, Lambda: 1.8364760011950164e-07\n",
      "\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 7s 223us/sample - loss: 47.2293 - acc: 0.0991\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 4s 109us/sample - loss: 16.6428 - acc: 0.0987\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 235.5644 - acc: 0.0991\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 29.8483 - acc: 0.1004\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 24.5497 - acc: 0.1000\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 58.1505 - acc: 0.0970\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 160.7226 - acc: 0.1012\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 18.3498 - acc: 0.1010\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 153.0078 - acc: 0.1005\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 87.6407 - acc: 0.1011\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 16.8442 - acc: 0.1013\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 121.1445 - acc: 0.0993\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 55.7509 - acc: 0.1015\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 54.6003 - acc: 0.0988\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 15.9102 - acc: 0.0977\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 14.5540 - acc: 0.0999\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 21106.9642 - acc: 0.0985\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 1804.3638 - acc: 0.0990\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 74.8985 - acc: 0.0999\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 71.0399 - acc: 0.1033\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 5345.2188 - acc: 0.0985\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 867.5070 - acc: 0.0994\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 60.8608 - acc: 0.0970\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 15.7075 - acc: 0.1011\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 144.5095 - acc: 0.0981\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 33.5237 - acc: 0.0990\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 124.9602 - acc: 0.0980\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 10581.7795 - acc: 0.1019\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 323.7084 - acc: 0.0999\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 26.9840 - acc: 0.0988\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 18.0415 - acc: 0.1004\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 14.7986 - acc: 0.0998\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 243.6819 - acc: 0.1000\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 39.6465 - acc: 0.0998\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 11662.4039 - acc: 0.0979\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 537.4380 - acc: 0.0991\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 28.7273 - acc: 0.1005\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 255.2151 - acc: 0.0987\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 118.1658 - acc: 0.0978\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 522.2560 - acc: 0.0988\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 690.1660 - acc: 0.1009\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 17500.9733 - acc: 0.1017\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 27406.1927 - acc: 0.1001\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 957.0772 - acc: 0.1001\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 9681.2981 - acc: 0.0972\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 28069.8677 - acc: 0.09962s - loss\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 781.3899 - acc: 0.0990\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 41.3860 - acc: 0.0983s - loss: 44.9003 - a\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 19.0862 - acc: 0.0979\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 14.8932 - acc: 0.0996\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 8684.9169 - acc: 0.0995\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 1046.9502 - acc: 0.0978\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 122.3736 - acc: 0.0955 - loss: 57.242\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 229.5475 - acc: 0.0983\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 19.9637 - acc: 0.0993\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 14.6624 - acc: 0.0990\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 45.4201 - acc: 0.0997\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 325.5086 - acc: 0.0980\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 26.3261 - acc: 0.0983\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 5262.5876 - acc: 0.0978\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 15616.3463 - acc: 0.0983\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 398.1827 - acc: 0.0987\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 54.6872 - acc: 0.0992\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 18.4494 - acc: 0.1010\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 14.7004 - acc: 0.0985\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 1403.6236 - acc: 0.1003\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 245.8944 - acc: 0.0985\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 1718.1804 - acc: 0.0987\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 208.4669 - acc: 0.0982\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 104us/sample - loss: 20.8508 - acc: 0.1013\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 104us/sample - loss: 14.6924 - acc: 0.0993\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 14.5420 - acc: 0.0980\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 96839.6054 - acc: 0.0992\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 104us/sample - loss: 3335.6920 - acc: 0.1015\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 126.9824 - acc: 0.1001\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 17.8136 - acc: 0.0998\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 14.6359 - acc: 0.0969\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 213.4817 - acc: 0.0982\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 1344.0138 - acc: 0.0992\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 881.5928 - acc: 0.0993\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 39.2255 - acc: 0.0986\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 6209.3151 - acc: 0.1003\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 9909.4312 - acc: 0.0999\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 393.8330 - acc: 0.1007\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 24.7279 - acc: 0.0995\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 4873.7199 - acc: 0.0966\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 596.5750 - acc: 0.0999s - loss: 721.0109 - acc\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 116.0489 - acc: 0.0996\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 373.7812 - acc: 0.0985\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 30.5324 - acc: 0.0982\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 14.9578 - acc: 0.0988\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 14.5673 - acc: 0.0998\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 509.9184 - acc: 0.0988\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 49.0656 - acc: 0.0996\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 15.2764 - acc: 0.1010\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 54532.4262 - acc: 0.1012\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 1917.8539 - acc: 0.0988\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 699.6384 - acc: 0.1015\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 32.6951 - acc: 0.0981\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 15.1201 - acc: 0.0998\n",
      "Try 6/100: Best_val_acc: [15.08482776187715, 0.09854167], lr: 705.7527761906896, Lambda: 5.983504201857005e-05\n",
      "\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 8s 239us/sample - loss: 24.4607 - acc: 0.1021\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 15.9604 - acc: 0.1011\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 15.6895 - acc: 0.1026\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 15.5726 - acc: 0.1015\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 170.4732 - acc: 0.0994\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 30.8298 - acc: 0.1017\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 17.5684 - acc: 0.1022\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 26.7381 - acc: 0.0990\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 25.9728 - acc: 0.0997\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 17.3640 - acc: 0.0985\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 22.9693 - acc: 0.1010\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 18.8909 - acc: 0.0984\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 16.5621 - acc: 0.0980\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 17.6613 - acc: 0.1004\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 17.5865 - acc: 0.0978\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 28.7042 - acc: 0.1010\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - ETA: 0s - loss: 17.0084 - acc: 0.10 - 3s 100us/sample - loss: 16.9619 - acc: 0.1009\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 15.7158 - acc: 0.1032\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 15.2158 - acc: 0.1007\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 20.4137 - acc: 0.0988\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 19.3105 - acc: 0.0994\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2985.6277 - acc: 0.1007\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 4134.6986 - acc: 0.1012\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 137.0381 - acc: 0.1002\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 19.7935 - acc: 0.1000\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 18.2123 - acc: 0.1001\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 15.2982 - acc: 0.0996\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 15.4000 - acc: 0.1011\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 52.9464 - acc: 0.0987\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 23.2050 - acc: 0.1000\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 18.2402 - acc: 0.1021\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 15.5269 - acc: 0.1023\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 24.2706 - acc: 0.0982\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 15.4574 - acc: 0.1013\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 15.7292 - acc: 0.1000\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 16.1658 - acc: 0.1001\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 15.9861 - acc: 0.1011\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 88.6911 - acc: 0.0997\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 18.8068 - acc: 0.1009\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 17.8300 - acc: 0.1018\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 17.0735 - acc: 0.1005\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 18.0851 - acc: 0.1015\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 21.0849 - acc: 0.0985\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 18.7822 - acc: 0.0985\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 17.1290 - acc: 0.1012\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 28.4705 - acc: 0.1020\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 15.3313 - acc: 0.1017\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 15.0353 - acc: 0.1004\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 43.8799 - acc: 0.1019\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 17.7392 - acc: 0.1012\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 5s 149us/sample - loss: 16.3559 - acc: 0.1013\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 5s 158us/sample - loss: 15.6940 - acc: 0.1003\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 5s 134us/sample - loss: 18.8598 - acc: 0.0996 - loss: 18.7730 - acc: \n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 5s 139us/sample - loss: 62.5120 - acc: 0.1007\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 4s 114us/sample - loss: 17.6091 - acc: 0.1019\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 4s 105us/sample - loss: 25.7730 - acc: 0.1000\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 4s 114us/sample - loss: 15.1242 - acc: 0.1017\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 4s 119us/sample - loss: 97.8873 - acc: 0.1000\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 4s 109us/sample - loss: 17.1420 - acc: 0.0982\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 4s 116us/sample - loss: 16.7867 - acc: 0.1022\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 4s 111us/sample - loss: 71.7343 - acc: 0.1003\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 4s 105us/sample - loss: 16.9303 - acc: 0.1015\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 104us/sample - loss: 14.8077 - acc: 0.1016\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 26.4738 - acc: 0.1023\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 15.2014 - acc: 0.0997\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 37.0983 - acc: 0.0993\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 17.5710 - acc: 0.1011\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 23.6566 - acc: 0.0993\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 15.7294 - acc: 0.0995\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 17.1852 - acc: 0.1017\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 14.6899 - acc: 0.1000\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 4s 113us/sample - loss: 42.8107 - acc: 0.1021\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 103.2903 - acc: 0.0982\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 4s 111us/sample - loss: 123.0767 - acc: 0.1012\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 4s 112us/sample - loss: 20.5855 - acc: 0.1018\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 17.7555 - acc: 0.0997\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 4s 111us/sample - loss: 21.3142 - acc: 0.1008\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 15.0157 - acc: 0.1026\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 4s 111us/sample - loss: 18.9399 - acc: 0.1000\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - ETA: 0s - loss: 20.5279 - acc: 0.10 - 3s 102us/sample - loss: 20.4273 - acc: 0.1015\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 4s 104us/sample - loss: 909.1645 - acc: 0.0997\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 4s 108us/sample - loss: 406.3038 - acc: 0.0990\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 25.9822 - acc: 0.1014\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 4s 112us/sample - loss: 15.7599 - acc: 0.1015\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 985.7058 - acc: 0.1018\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 84.9059 - acc: 0.0998\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 16.3540 - acc: 0.1007\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 39.3837 - acc: 0.0996\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 45.1155 - acc: 0.1002\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 19.5070 - acc: 0.0991\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 16.2384 - acc: 0.1006\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 22.4872 - acc: 0.1012\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 40.1933 - acc: 0.1010\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 17.1608 - acc: 0.0998\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 15.0937 - acc: 0.0990\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 18.1831 - acc: 0.0991\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 39.1240 - acc: 0.1011\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 506.6720 - acc: 0.0995\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 29.4916 - acc: 0.0990\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 15.4390 - acc: 0.1010\n",
      "Try 7/100: Best_val_acc: [16.697347355797177, 0.10014881], lr: 73.27545779098233, Lambda: 0.002042776313176996\n",
      "\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 7s 223us/sample - loss: 2.7640 - acc: 0.0955\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7619 - acc: 0.0980\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7746 - acc: 0.09502s\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7668 - acc: 0.0973\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7587 - acc: 0.0994\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7755 - acc: 0.0940\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7626 - acc: 0.09800s - loss: 2.7631 - ac\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7713 - acc: 0.0973\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7684 - acc: 0.0972\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7675 - acc: 0.09870s - loss: 2.7724 - acc:\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7600 - acc: 0.0979\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7661 - acc: 0.0989\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7622 - acc: 0.0975\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7601 - acc: 0.0993\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7614 - acc: 0.0989\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7671 - acc: 0.0979\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7684 - acc: 0.0963\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7640 - acc: 0.0958\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7659 - acc: 0.0957\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.7661 - acc: 0.0978\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7651 - acc: 0.0952\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7687 - acc: 0.0959\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7639 - acc: 0.0966\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7610 - acc: 0.0957\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7598 - acc: 0.0976\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7596 - acc: 0.1004\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7634 - acc: 0.0968\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7614 - acc: 0.0996\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7672 - acc: 0.0951\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7714 - acc: 0.09771s - loss: 2.7713 -\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7638 - acc: 0.0959\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7577 - acc: 0.09660s - loss: 2.7606 - acc: 0.09\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7695 - acc: 0.09721s - loss: 2.771\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7629 - acc: 0.0966\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7667 - acc: 0.09541s - loss: \n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7611 - acc: 0.09751s - loss: 2.7615\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7594 - acc: 0.0979\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7721 - acc: 0.09741s - loss: 2.77\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7687 - acc: 0.09831s - loss: 2.7795 - acc: 0 - ETA: 1s - loss: 2.7766 - acc: 0.098 - ETA: 1s - loss: 2.774\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7700 - acc: 0.0953\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7626 - acc: 0.0961\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7657 - acc: 0.0974\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7629 - acc: 0.1001\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7606 - acc: 0.09580s - loss: 2.7600 - acc: \n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7564 - acc: 0.0988\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.7692 - acc: 0.0968s -\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7618 - acc: 0.1012\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7642 - acc: 0.0990\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7632 - acc: 0.0979\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7692 - acc: 0.0965\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7654 - acc: 0.0988\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7561 - acc: 0.0974\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7622 - acc: 0.0974\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7675 - acc: 0.0985\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7660 - acc: 0.0983\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7682 - acc: 0.0956\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7589 - acc: 0.0967\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7672 - acc: 0.0979\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7633 - acc: 0.0966\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7742 - acc: 0.0958\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - ETA: 0s - loss: 2.7700 - acc: 0.094 - 3s 98us/sample - loss: 2.7686 - acc: 0.0952\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7639 - acc: 0.0965\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7714 - acc: 0.0962\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7603 - acc: 0.0960\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7659 - acc: 0.09402s\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7630 - acc: 0.09730s - loss: 2.7603 - acc: \n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7637 - acc: 0.0970\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7638 - acc: 0.0975\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7695 - acc: 0.09621s - loss: 2.7701\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7621 - acc: 0.0976\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7654 - acc: 0.0985\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7587 - acc: 0.0955\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7605 - acc: 0.0988\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7652 - acc: 0.0975\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7615 - acc: 0.0974\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7591 - acc: 0.0945\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7601 - acc: 0.0999\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7685 - acc: 0.0955\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7639 - acc: 0.1003\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7606 - acc: 0.1007\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7653 - acc: 0.0958\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7639 - acc: 0.0969\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7638 - acc: 0.0965\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7711 - acc: 0.09491s - loss: 2.\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 2.7607 - acc: 0.0961\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7655 - acc: 0.0969\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7618 - acc: 0.0953s - loss: 2.7614 - acc: 0.\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7711 - acc: 0.0971\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7582 - acc: 0.0988\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s 102us/sample - loss: 2.7647 - acc: 0.0979\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7538 - acc: 0.0973\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7579 - acc: 0.0996\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.7629 - acc: 0.0967\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7563 - acc: 0.1000\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7720 - acc: 0.0948\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7591 - acc: 0.0982\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7712 - acc: 0.09750s - loss: 2.7714 - acc: 0.09\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7634 - acc: 0.0926\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7692 - acc: 0.0975\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7665 - acc: 0.0945\n",
      "Try 8/100: Best_val_acc: [2.4965011703400384, 0.094166666], lr: 1.3121631650213083e-07, Lambda: 3.279471520769524e-07\n",
      "\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 8s 230us/sample - loss: 2.8360 - acc: 0.1004\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.8370 - acc: 0.1013\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8342 - acc: 0.1016\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8310 - acc: 0.1003\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8411 - acc: 0.1015\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8385 - acc: 0.09990s - loss: 2.8398 - acc: 0.09 - ETA: 0s - loss: 2.8401 - acc: 0.\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.8230 - acc: 0.1019\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8324 - acc: 0.1026\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8348 - acc: 0.1014\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8404 - acc: 0.1009\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8293 - acc: 0.1026\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8213 - acc: 0.1025\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8287 - acc: 0.09920s - loss: 2.8265 - acc: 0.09\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.8355 - acc: 0.1033\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8345 - acc: 0.0992\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8398 - acc: 0.1016\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8187 - acc: 0.1015\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8276 - acc: 0.1010\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.8249 - acc: 0.1012\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8241 - acc: 0.10180s - loss: 2.8248 - acc\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8258 - acc: 0.1019\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8254 - acc: 0.10221s - loss: \n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8237 - acc: 0.1006\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8300 - acc: 0.1037\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8192 - acc: 0.1021\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8216 - acc: 0.1029\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8169 - acc: 0.1029\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.8205 - acc: 0.1038\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8187 - acc: 0.10122s - \n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.8198 - acc: 0.0987\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8232 - acc: 0.10242s - lo\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.8188 - acc: 0.0997\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8130 - acc: 0.1044\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8166 - acc: 0.0992\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.8240 - acc: 0.1030\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.8229 - acc: 0.0996\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8199 - acc: 0.1030\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8141 - acc: 0.1026\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8087 - acc: 0.1031\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8101 - acc: 0.1011\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8088 - acc: 0.10281s - loss: 2.8022 - \n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8100 - acc: 0.1020\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8123 - acc: 0.1012\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8017 - acc: 0.1036\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8058 - acc: 0.1032\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.8103 - acc: 0.1051\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8044 - acc: 0.1031\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.8109 - acc: 0.1020\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8059 - acc: 0.1017\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8035 - acc: 0.1020\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.8048 - acc: 0.1031\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8062 - acc: 0.1042\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8120 - acc: 0.1016\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 3s 103us/sample - loss: 2.8063 - acc: 0.1029\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.8014 - acc: 0.1033\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.8040 - acc: 0.1015\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8036 - acc: 0.1004\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.8006 - acc: 0.1026\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.8025 - acc: 0.1015\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8133 - acc: 0.1026\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.8036 - acc: 0.1051\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7931 - acc: 0.1039\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.7999 - acc: 0.1043\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 3s 100us/sample - loss: 2.8012 - acc: 0.1029\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7881 - acc: 0.1050\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.8026 - acc: 0.0982\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7986 - acc: 0.1008\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7964 - acc: 0.1021\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7880 - acc: 0.1058\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7909 - acc: 0.1009\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7907 - acc: 0.1037\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.7891 - acc: 0.1037\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 3s 98us/sample - loss: 2.7929 - acc: 0.1031\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7892 - acc: 0.1007\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7869 - acc: 0.1027\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7905 - acc: 0.1035\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7911 - acc: 0.1004\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7933 - acc: 0.1021\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7902 - acc: 0.1036\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 3s 99us/sample - loss: 2.7872 - acc: 0.1030\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7872 - acc: 0.1028\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7818 - acc: 0.10142s - los - ETA: 0s - loss: 2.7786 - acc: \n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7966 - acc: 0.1010\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7818 - acc: 0.10382s \n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7853 - acc: 0.1001\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7803 - acc: 0.1021\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s 94us/sample - loss: 2.7876 - acc: 0.09991s - loss: 2\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7851 - acc: 0.1032\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7866 - acc: 0.1044\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7836 - acc: 0.1021\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7856 - acc: 0.10241s - loss: 2\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7759 - acc: 0.1023\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7864 - acc: 0.1048\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 3s 95us/sample - loss: 2.7855 - acc: 0.1043\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7867 - acc: 0.1020\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - ETA: 0s - loss: 2.7839 - acc: 0.101 - 3s 95us/sample - loss: 2.7832 - acc: 0.1017\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7837 - acc: 0.1064\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 3s 97us/sample - loss: 2.7808 - acc: 0.1018\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7834 - acc: 0.1019\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 3s 96us/sample - loss: 2.7811 - acc: 0.1009\n",
      "Try 9/100: Best_val_acc: [2.4954848062424433, 0.10654762], lr: 3.3249912946339177e-06, Lambda: 0.0033156850773011348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,10):\n",
    "    lr = math.pow(10, np.random.uniform(-7.0, 3.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
    "    best_acc = train_and_test_loop1(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We found that in cycle 2 there were best results with: Try 2/100: Best_val_acc: [0.6108700076100372, 0.8087798], lr: 0.02098856385734849, Lambda: 0.0003801922142446604\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning model with the optimised hyper parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 3s 101us/sample - loss: 2.5123 - acc: 0.1119\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 2s 49us/sample - loss: 2.2764 - acc: 0.1667\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 2.0652 - acc: 0.2510\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 1.8530 - acc: 0.34071s - loss: \n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 1.6823 - acc: 0.4125\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 1s 45us/sample - loss: 1.5444 - acc: 0.4685\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 1.4505 - acc: 0.5038\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 1.3683 - acc: 0.5389\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 1s 45us/sample - loss: 1.3212 - acc: 0.5585\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 1.2579 - acc: 0.5851\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 2s 51us/sample - loss: 1.2101 - acc: 0.6023\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 1.1676 - acc: 0.6178\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 1.1292 - acc: 0.6316\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 1.1064 - acc: 0.64310s - loss: 1.1122 - acc\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 1.0691 - acc: 0.6592\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 1.0455 - acc: 0.6688\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 1s 45us/sample - loss: 1.0229 - acc: 0.6728\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 1.0080 - acc: 0.67771s - loss: \n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.9907 - acc: 0.6871\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.9622 - acc: 0.6943\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.9427 - acc: 0.7040\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.9375 - acc: 0.7049\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.9265 - acc: 0.71030s - loss: 0.9229 - acc\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.9197 - acc: 0.7117\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 1s 45us/sample - loss: 0.8911 - acc: 0.7191\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.8850 - acc: 0.7251\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 1s 45us/sample - loss: 0.8716 - acc: 0.7269\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.8599 - acc: 0.7315\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.8460 - acc: 0.7343\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.8527 - acc: 0.7345\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.8320 - acc: 0.7390\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.8280 - acc: 0.7410\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.8211 - acc: 0.7433\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.8140 - acc: 0.7488\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 2s 56us/sample - loss: 0.7982 - acc: 0.75430s - loss: 0.7966 - acc: 0.\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 0.8041 - acc: 0.75090s - loss: 0.7947 - ac\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.7909 - acc: 0.7546\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 1s 45us/sample - loss: 0.7834 - acc: 0.7590\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.7809 - acc: 0.7598\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.7757 - acc: 0.7602\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.7727 - acc: 0.7604\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.7533 - acc: 0.7664\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.7521 - acc: 0.7670\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.7425 - acc: 0.7709\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.7394 - acc: 0.7724\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7343 - acc: 0.7736\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.7258 - acc: 0.7786\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 1s 45us/sample - loss: 0.7200 - acc: 0.7780\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.7226 - acc: 0.7776\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 2s 56us/sample - loss: 0.7225 - acc: 0.7775\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.7063 - acc: 0.7829\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7092 - acc: 0.7821\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.7006 - acc: 0.7860\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.7014 - acc: 0.7841\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6917 - acc: 0.7874\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6921 - acc: 0.7862\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6966 - acc: 0.7851\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6871 - acc: 0.7900\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6924 - acc: 0.78681s - loss: 0.6\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6811 - acc: 0.7911\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6719 - acc: 0.7958\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6695 - acc: 0.7946\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.6700 - acc: 0.7935\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6634 - acc: 0.7982\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6665 - acc: 0.7951\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6636 - acc: 0.7968\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.6536 - acc: 0.8014\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6611 - acc: 0.7975\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6576 - acc: 0.7973\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.6411 - acc: 0.8038\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6557 - acc: 0.7990\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.6550 - acc: 0.7993\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 2s 54us/sample - loss: 0.6423 - acc: 0.8018\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 3s 75us/sample - loss: 0.6374 - acc: 0.8031\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 2s 64us/sample - loss: 0.6326 - acc: 0.8080\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 2s 55us/sample - loss: 0.6376 - acc: 0.8067\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6352 - acc: 0.80490s - loss: 0.6341 - acc: 0.808 - ETA: 0s - loss: 0.6363 - a\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6377 - acc: 0.8071\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6283 - acc: 0.8074\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 1s 41us/sample - loss: 0.6322 - acc: 0.8071\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6346 - acc: 0.8068\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6170 - acc: 0.8090\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 1s 41us/sample - loss: 0.6277 - acc: 0.8080\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6232 - acc: 0.8119\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 1s 41us/sample - loss: 0.6123 - acc: 0.8118\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6168 - acc: 0.8114\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 1s 41us/sample - loss: 0.6159 - acc: 0.8120\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 2s 61us/sample - loss: 0.6150 - acc: 0.8116\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 2s 54us/sample - loss: 0.6091 - acc: 0.8147\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6059 - acc: 0.8140\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6109 - acc: 0.8139\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6035 - acc: 0.8169\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 2s 61us/sample - loss: 0.6024 - acc: 0.8150\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6014 - acc: 0.8163\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.5945 - acc: 0.8183\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.5985 - acc: 0.8179\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.5942 - acc: 0.8199\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6033 - acc: 0.8163\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 2s 68us/sample - loss: 0.5842 - acc: 0.8222\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 0.5967 - acc: 0.8158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6922922841991697, 0.77758926]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.021\n",
    "Lambda = 0.000380\n",
    "train_and_test_loop1(100, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing our model with identified Parameters and Hyper Parameter as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 4s 120us/sample - loss: 2.5148 - acc: 0.1146\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 2.2626 - acc: 0.1730\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 1s 40us/sample - loss: 2.0738 - acc: 0.2480\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 1s 40us/sample - loss: 1.8939 - acc: 0.3188\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 1s 40us/sample - loss: 1.7325 - acc: 0.3885\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 1s 40us/sample - loss: 1.6208 - acc: 0.4396\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 1s 41us/sample - loss: 1.5050 - acc: 0.4862\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 1s 40us/sample - loss: 1.4216 - acc: 0.5222\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 2s 58us/sample - loss: 1.3640 - acc: 0.5429\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 2s 62us/sample - loss: 1.3049 - acc: 0.56970s - loss: 1.3038 - acc: \n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 1.2634 - acc: 0.5838\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 1.2229 - acc: 0.6045\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 1.1804 - acc: 0.6143\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 2s 57us/sample - loss: 1.1403 - acc: 0.6324\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 1.1077 - acc: 0.6440\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 1.0824 - acc: 0.6521\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 1.0684 - acc: 0.6568\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 1.0408 - acc: 0.6679\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 1.0021 - acc: 0.6829\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.9923 - acc: 0.6888\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.9734 - acc: 0.6913\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 0.9610 - acc: 0.6949\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.9394 - acc: 0.7046\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.9276 - acc: 0.7090\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.9049 - acc: 0.7173\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.8879 - acc: 0.7217\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 2s 50us/sample - loss: 0.8816 - acc: 0.7245\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 2s 50us/sample - loss: 0.8702 - acc: 0.7265\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 0.8567 - acc: 0.7317\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 2s 50us/sample - loss: 0.8541 - acc: 0.7356\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.8389 - acc: 0.7397\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.8229 - acc: 0.7436\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 2s 49us/sample - loss: 0.8193 - acc: 0.7446\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.8279 - acc: 0.7451\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.8006 - acc: 0.7537\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7963 - acc: 0.7526\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 0.7967 - acc: 0.7551\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.7844 - acc: 0.75790s - loss: 0.7813 - ac\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.7748 - acc: 0.7622\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.7748 - acc: 0.7631\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7645 - acc: 0.7651\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7572 - acc: 0.7663\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.7644 - acc: 0.7641\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 2s 47us/sample - loss: 0.7448 - acc: 0.7690\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7460 - acc: 0.7709\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.7447 - acc: 0.7705\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7247 - acc: 0.7763\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7291 - acc: 0.7769\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.7313 - acc: 0.7754\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.7178 - acc: 0.7807\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 2s 51us/sample - loss: 0.7089 - acc: 0.7822\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 0.7072 - acc: 0.7832\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 2s 48us/sample - loss: 0.7063 - acc: 0.7835\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.7023 - acc: 0.7834\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.7023 - acc: 0.7846\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6884 - acc: 0.7916\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6855 - acc: 0.7874\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6857 - acc: 0.7874\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6763 - acc: 0.7935\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6811 - acc: 0.7933\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6790 - acc: 0.7927\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 1s 45us/sample - loss: 0.6723 - acc: 0.7927\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6724 - acc: 0.7946\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6806 - acc: 0.7937\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6683 - acc: 0.7955\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6619 - acc: 0.7986\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.6588 - acc: 0.8001\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.6539 - acc: 0.8007\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.6590 - acc: 0.7989\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6492 - acc: 0.8009\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6480 - acc: 0.8004\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6580 - acc: 0.7984\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6496 - acc: 0.8031\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6480 - acc: 0.8032\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6344 - acc: 0.8053\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6364 - acc: 0.8063\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 2s 46us/sample - loss: 0.6349 - acc: 0.8066\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 2s 54us/sample - loss: 0.6333 - acc: 0.8049\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 2s 69us/sample - loss: 0.6331 - acc: 0.8079\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 2s 69us/sample - loss: 0.6346 - acc: 0.8074\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6280 - acc: 0.8081\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6198 - acc: 0.8111\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6218 - acc: 0.8099\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6178 - acc: 0.8135\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6179 - acc: 0.8097\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6158 - acc: 0.8116\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.6139 - acc: 0.8136\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6183 - acc: 0.8117\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6128 - acc: 0.8146\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.5994 - acc: 0.8189\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6116 - acc: 0.8148\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 2s 45us/sample - loss: 0.6107 - acc: 0.8129\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 1s 44us/sample - loss: 0.6133 - acc: 0.8115\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.6051 - acc: 0.8148\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.5929 - acc: 0.8208\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.5995 - acc: 0.8188\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.5974 - acc: 0.8222\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 1s 43us/sample - loss: 0.5917 - acc: 0.8195\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.5942 - acc: 0.8216\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 1s 42us/sample - loss: 0.5879 - acc: 0.8216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2452b4ba4a8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## hyperparameters\n",
    "iterations = 100\n",
    "learning_rate = 0.021\n",
    "Lambda = 0.000380\n",
    "hidden_nodes = 256\n",
    "output_nodes = 10\n",
    "\n",
    "model1 = Sequential()\n",
    "    \n",
    "model1.add(Dense(100, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(100, kernel_initializer='he_normal'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))    \n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(100, kernel_initializer='he_normal'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(70, kernel_initializer='he_normal'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    \n",
    "\n",
    "sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "model1.fit(X_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 3s 145us/sample - loss: 0.7828 - acc: 0.7559\n"
     ]
    }
   ],
   "source": [
    "results = model1.evaluate(X_test, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7558889\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 70)                7070      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                710       \n",
      "=================================================================\n",
      "Total params: 131,960\n",
      "Trainable params: 131,220\n",
      "Non-trainable params: 740\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
